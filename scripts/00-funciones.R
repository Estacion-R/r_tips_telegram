##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                Funci√≥n para armar una base de tuits de cero              ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
token_openai <- Sys.getenv("OPENAI_API_KEY")

crear_base_historica <- function(){
  
  # Link a la hoja de c√°lculo
  url <- "https://docs.google.com/spreadsheets/d/1OKGyVgAy1YhKfaGP_p0rwXWdVnQfovFRsgzo5qRQ3eo/edit#gid=0"
  
  # Habilito acceso p√∫blico
  googlesheets4::gs4_deauth()
  
  # Leo hoja de c√°lculo
  base_r_tips <- googlesheets4::read_sheet(url, 
                                           sheet = "Desarrollo")
  
  ### Las que se repitieron muchas veces (ahora basado en web)
  tip1 <- base_r_tips |>
    dplyr::filter(
      stringr::str_detect(
        web,
        "clean|numeric_to|Gente Sociable|pointblank|ARTofR|madre|read_sheet|Quarto|coalesce|of Us|Metropolitana"))
  
  base_r_tips <- base_r_tips |>
    dplyr::bind_rows(tip1)
  
  conteo_tuits <- base_r_tips |> 
    dplyr::group_by(web) |> 
    dplyr::summarise(cant_tuits = dplyr::n()) |> 
    dplyr::ungroup()
  
  base_r_tips <- base_r_tips |> 
    dplyr::left_join(conteo_tuits, by = "web")
  
  if(file.exists("data/r_tips_historial.rds")){
    
    file.remove("data/r_tips_historial.rds")
    
    saveRDS(base_r_tips, "data/r_tips_historial.rds")
    
  } else {
    
    saveRDS(base_r_tips, "data/r_tips_historial.rds")
  }
}

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                  Funci√≥n para Seleccionar un tuit al azar                ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

seleccionar_tuit <- function(base){
  ### Saco al azar uno de esos tuits
  base_tuit <- base |> 
    dplyr::slice_min(order_by = cant_tuits, n = 2) |> 
    dplyr::select(-cant_tuits) |> 
    dplyr::sample_n(1)
  
  return(base_tuit)
}

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                  Funci√≥n para Seleccionar 3 tips                        ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

seleccionar_3_tips <- function(r_tips, base_hist) {
  ### TUITS INEDITOS
  tip_inedito <- r_tips |> 
    dplyr::anti_join(base_hist, by = "web")
  
  tips_seleccionados <- data.frame()
  
  ### ESTRATEGIA GRADUAL
  if(nrow(tip_inedito) >= 3){
    # Caso 1: Hay 3+ in√©ditos, seleccionar 3 in√©ditos
    tips_seleccionados <- tip_inedito |> 
      dplyr::sample_n(3)
    
  } else if(nrow(tip_inedito) > 0) {
    # Caso 2: Hay 1-2 in√©ditos, completar con menos publicados
    tips_seleccionados <- tip_inedito
    
    # Completar con los menos publicados (excluyendo los ya seleccionados)
    tips_restantes <- 3 - nrow(tip_inedito)
    
    tips_menos_publicados <- base_hist |> 
      dplyr::anti_join(tips_seleccionados, by = "web") |> 
      dplyr::slice_min(order_by = cant_tuits, n = tips_restantes * 2) |> 
      dplyr::select(-cant_tuits) |> 
      dplyr::sample_n(tips_restantes)
    
    tips_seleccionados <- tips_seleccionados |> 
      dplyr::bind_rows(tips_menos_publicados)
    
  } else {
    # Caso 3: No hay in√©ditos, seleccionar 3 menos publicados
    tips_seleccionados <- base_hist |> 
      dplyr::slice_min(order_by = cant_tuits, n = 6) |> 
      dplyr::select(-cant_tuits) |> 
      dplyr::sample_n(3)
  }
  
  return(tips_seleccionados)
}



##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                    Funci√≥n para obtener contenido de URLs               ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

obtener_contenido_url <- function(url) {
  tryCatch({
    # Usar httr para obtener el contenido
    response <- httr::GET(url, httr::timeout(30))
    
    if (httr::status_code(response) == 200) {
      # Obtener el contenido HTML
      contenido_html <- httr::content(response, as = "text", encoding = "UTF-8")
      
      # Extraer texto del HTML (b√°sico)
      # Remover tags HTML b√°sicos
      texto <- gsub("<script[^>]*>.*?</script>", "", contenido_html, ignore.case = TRUE)
      texto <- gsub("<style[^>]*>.*?</style>", "", texto, ignore.case = TRUE)
      texto <- gsub("<[^>]+>", " ", texto)
      texto <- gsub("\\s+", " ", texto)
      texto <- trimws(texto)
      
      # Limitar a los primeros 3000 caracteres para evitar prompts muy largos
      if (nchar(texto) > 3000) {
        texto <- substr(texto, 1, 3000)
        texto <- paste0(texto, "...")
      }
      
      return(list(
        exito = TRUE,
        contenido = texto,
        url = url
      ))
    } else {
      return(list(
        exito = FALSE,
        error = paste("Error HTTP:", httr::status_code(response)),
        url = url
      ))
    }
  }, error = function(e) {
    return(list(
      exito = FALSE,
      error = paste("Error al acceder a URL:", e$message),
      url = url
    ))
  })
}

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                    Funci√≥n para armar el tuit a publicar                 ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
### Armado de tuit
library(ellmer)
library(glue)
library(httr)

armar_contenido <- function(base, model = "gpt-3.5-turbo") {
  # Detectar si es un solo tip o m√∫ltiples tips
  if(nrow(base) == 1) {
    return(armar_contenido_simple(base, model))
  } else {
    return(armar_contenido_multiple(base, model))
  }
}

# Funci√≥n de compatibilidad hacia atr√°s
armar_tuit <- function(base, model = "gpt-3.5-turbo") {
  contenido <- armar_contenido(base, model)
  return(contenido$redes)
}

# Funci√≥n para un solo tip - genera ambos formatos
armar_contenido_simple <- function(base, model = "gpt-3.5-turbo") {
  web <- base$web
  
  # Obtener contenido real de la URL
  contenido_url <- obtener_contenido_url(web)
  
  if (!contenido_url$exito) {
    stop(paste("Error al obtener contenido de", web, ":", contenido_url$error))
  }
  
  # PROMPT PARA REDES SOCIALES CON CONTENIDO REAL
  prompt_redes <- glue(
    "Eres el redactor de contenido de 'Estaci√≥n R'. Te proporciono el contenido REAL de esta URL: {web}\n\n",
    
    "CONTENIDO REAL DE LA P√ÅGINA:\n",
    "---\n{contenido_url$contenido}\n---\n\n",
    
    "INSTRUCCIONES:\n",
    "- Analiza √öNICAMENTE el contenido proporcionado arriba\n",
    "- Identifica el TEMA al que pertenece: visualizaci√≥n, procesamiento, bibliograf√≠a, notas, referentes, experiencias, etc.\n",
    "- Identifica el nombre EXACTO del paquete/herramienta seg√∫n aparece en el contenido\n",
    "- Describe SOLO las funciones/caracter√≠sticas mencionadas en el texto\n\n",
    
    "FORMATO PARA REDES SOCIALES:\n",
    "- Estructura: [TEMA] Nombre exacto seg√∫n el contenido\n",
    "- Descripci√≥n basada 100% en el contenido real\n",
    "- 2-3 caracter√≠sticas verificadas del texto\n",
    "- Tono argentino con voseo: 'les compartimos desde Estaci√≥n R'\n",
    "- Incluye emojis relevantes: üí° üéì üìä üõ†Ô∏è üìà ‚ö°\n",
    "- Al final: mensaje de engagement pidiendo experiencias de la audiencia\n",
    "- Hashtags: Siempre incluir #RStats #RStatsES #EstacionR #Rtips + otros relevantes seg√∫n popularidad\n",
    "- 800-1000 caracteres total\n\n",
    
    "IMPORTANTE: Solo usa informaci√≥n literal del contenido. NO inventes conexiones tem√°ticas."
  )
  
  # PROMPT PARA NEWSLETTER CON CONTENIDO REAL
  prompt_newsletter <- glue(
    "Bas√°ndote en el MISMO contenido real, crea una versi√≥n para newsletter de Mailchimp:\n\n",
    
    "CONTENIDO REAL DE LA P√ÅGINA:\n",
    "---\n{contenido_url$contenido}\n---\n\n",
    
    "FORMATO NEWSLETTER:\n",
    "1. T√≠tulo atractivo para email\n",
    "2. Introducci√≥n profesional sobre el recurso\n",
    "3. Desarrollo detallado basado √∫nicamente en el contenido proporcionado\n",
    "4. Casos de uso espec√≠ficos mencionados en el texto\n",
    "5. Beneficios concretos extra√≠dos del contenido\n",
    "6. Call-to-action para explorar el recurso\n\n",
    
    "CARACTER√çSTICAS:\n",
    "- Extensi√≥n: 1500-2000 caracteres\n",
    "- Tono profesional pero cercano\n",
    "- Estructura clara con p√°rrafos separados\n",
    "- Solo informaci√≥n literal del contenido proporcionado\n",
    "- Enfoque educativo profundo\n\n",
    
    "IMPORTANTE: Usar √öNICAMENTE informaci√≥n que aparece en el contenido proporcionado."
  )
  
  chat <- ellmer::chat_openai(model = model, api_key = token_openai)
  
  # Generar contenido para redes
  contenido_redes <- chat$chat(prompt_redes)
  redes_final <- if (!is.na(web) && nzchar(web)) glue("{contenido_redes}\n\nüåê {web}") else contenido_redes
  
  # Generar contenido para newsletter
  contenido_newsletter <- chat$chat(prompt_newsletter)
  newsletter_final <- if (!is.na(web) && nzchar(web)) glue("{contenido_newsletter}\n\nüåê Recurso: {web}") else contenido_newsletter
  
  return(list(
    redes = redes_final,
    newsletter = newsletter_final
  ))
}

# Nueva funci√≥n para m√∫ltiples tips - genera ambos formatos
armar_contenido_multiple <- function(base, model = "gpt-3.5-turbo") {
  webs <- paste(base$web, collapse = "\n")
  
  # Obtener contenido real de cada URL
  contenidos_urls <- list()
  contenidos_texto <- ""
  
  for(i in 1:nrow(base)) {
    url <- base$web[i]
    contenido <- obtener_contenido_url(url)
    
    if (!contenido$exito) {
      stop(paste("Error al obtener contenido de", url, ":", contenido$error))
    }
    
    contenidos_urls[[i]] <- contenido
    contenidos_texto <- paste0(contenidos_texto, 
                              "\n=== CONTENIDO DE ", url, " ===\n",
                              contenido$contenido, "\n")
  }
  
  # PROMPT PARA REDES SOCIALES CON CONTENIDO REAL
  urls_con_contenido_redes <- ""
  for(i in 1:nrow(base)) {
    urls_con_contenido_redes <- paste0(urls_con_contenido_redes, 
                                      "URL ", i, ": ", base$web[i], "\n")
  }
  
  prompt_redes <- glue(
    "Eres el redactor de contenido de 'Estaci√≥n R'. Te proporciono el contenido REAL de estos 3 recursos:\n\n",
    
    "URLS DE LOS RECURSOS:\n",
    "{urls_con_contenido_redes}\n",
    
    "CONTENIDO REAL DE LAS 3 P√ÅGINAS:\n",
    "---\n{contenidos_texto}\n---\n\n",
    
    "INSTRUCCIONES:\n",
    "- Analiza √öNICAMENTE el contenido proporcionado arriba\n",
    "- Para cada recurso:\n",
    "  ‚Ä¢ Identifica el TEMA: visualizaci√≥n, procesamiento, bibliograf√≠a, notas, referentes, experiencias, etc.\n",
    "  ‚Ä¢ Identifica el nombre EXACTO seg√∫n aparece en su contenido\n",
    "  ‚Ä¢ Describe SOLO funcionalidades mencionadas en el texto\n",
    "- NO busques conexiones entre los recursos\n",
    "- Presenta cada uno de forma independiente\n\n",
    
    "FORMATO PARA REDES SOCIALES:\n",
    "- Inicio obligatorio: '¬°Llegaron los Rtips de la semana!' seguido de una l√≠nea en blanco\n",
    "- Luego: '[SELECCI√ìN] 3 recursos de R'\n",
    "- Para cada recurso:\n",
    "  [EMOJI RELACIONADO AL CONTENIDO] **[TEMA] Nombre exacto**: Descripci√≥n verificada del contenido (1-2 l√≠neas)\n",
    "  üåê [URL correspondiente]\n",
    "- Elige emojis espec√≠ficos seg√∫n el contenido: üìä visualizaci√≥n, üõ†Ô∏è procesamiento, üìö bibliograf√≠a, üéì cursos, üåç mapas, ü§ñ machine learning, etc.\n",
    "- NO hagas conexiones entre los 3 recursos\n",
    "- Al final: mensaje de engagement: '¬øConoc√≠as o usaste alguno de estos paquetes? Contanos o compart√≠ lo que hayas hecho que lo difundimos'\n",
    "- Tono argentino con voseo desde Estaci√≥n R\n",
    "- Hashtags: Siempre incluir #RStats #RStatsES #EstacionR #Rtips + otros relevantes seg√∫n popularidad\n",
    "- 1000-1300 caracteres total\n\n",
    
    "IMPORTANTE: Solo usa informaci√≥n literal del contenido. NO inventes conexiones entre recursos."
  )
  
  # PROMPT PARA NEWSLETTER CON CONTENIDO REAL
  urls_con_contenido <- ""
  for(i in 1:nrow(base)) {
    urls_con_contenido <- paste0(urls_con_contenido, 
                                "URL ", i, ": ", base$web[i], "\n")
  }
  
  prompt_newsletter <- glue(
    "Bas√°ndote en el MISMO contenido real, crea una versi√≥n detallada para newsletter:\n\n",
    
    "URLS DE LOS RECURSOS:\n",
    "{urls_con_contenido}\n",
    
    "CONTENIDO REAL DE LAS 3 P√ÅGINAS:\n",
    "---\n{contenidos_texto}\n---\n\n",
    
    "FORMATO NEWSLETTER:\n",
    "1. T√≠tulo atractivo para email\n",
    "2. Introducci√≥n profesional sobre la selecci√≥n\n",
    "3. Cada recurso desarrollado:\n",
    "   - Subt√≠tulo con nombre exacto del contenido\n",
    "   - Descripci√≥n detallada basada √∫nicamente en el contenido proporcionado\n",
    "   - Casos de uso espec√≠ficos mencionados en el texto\n",
    "   - Beneficios concretos extra√≠dos del contenido\n",
    "   - INMEDIATAMENTE despu√©s: üåê [URL correspondiente del recurso]\n",
    "4. Conclusi√≥n integradora\n",
    "5. Call-to-action para explorar los recursos\n\n",
    
    "CARACTER√çSTICAS:\n",
    "- Extensi√≥n: 1500-2000 caracteres total (m√°ximo 2000)\n",
    "- Cada recurso: informaci√≥n concisa pero detallada del contenido proporcionado\n",
    "- Tono profesional pero cercano\n",
    "- Estructura clara con subt√≠tulos\n",
    "- Enfoque educativo profundo\n\n",
    
    "IMPORTANTE: Usar √öNICAMENTE informaci√≥n literal del contenido proporcionado."
  )
  
  chat <- ellmer::chat_openai(model = model, api_key = token_openai)
  
  # Generar contenido para redes
  contenido_redes <- chat$chat(prompt_redes)
  # Las URLs ya est√°n incluidas en cada descripci√≥n, no las agregamos al final
  redes_final <- contenido_redes
  
  # Generar contenido para newsletter
  contenido_newsletter <- chat$chat(prompt_newsletter)
  # Las URLs ya est√°n incluidas en cada descripci√≥n, no las agregamos al final
  newsletter_final <- contenido_newsletter
  
  return(list(
    redes = redes_final,
    newsletter = newsletter_final
  ))
}

# Funci√≥n de compatibilidad para m√∫ltiples tips
armar_tuit_multiple <- function(base, model = "gpt-3.5-turbo") {
  contenido <- armar_contenido_multiple(base, model)
  return(contenido$redes)
}




##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                              Preparar im√°gen                             ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

library(httr)
library(jsonlite)
library(glue)

genera_imagen_tip_dalle <- function(tip, 
                                    output_path = tempfile(fileext = ".png"),
                                    api_key = Sys.getenv("OPENAI_API_KEY")) {
  # Prompt visual consistente y claro
  prompt <- glue(
    "Dise√±a una imagen tipo carrusel para Instagram, de estilo minimalista, profesional y educativo, para ilustrar el siguiente tip de R: '{tip}'. ",
    "El fondo debe ser azul (#405BFF) o amarillo (#EAFF38). Si es un paquete de R, el logo original debe estar en el centro",
    "con tipograf√≠a Ubuntu clara y legible (preferentemente Ubuntu). Deja m√°rgenes generosos y que el dise√±o sea minimalista y limpio. ",
    "Incluye un espacio en la esquina inferior derecha para el logo horizontal de Estaci√≥n R (aqu√≠ el link al logo: https://github.com/Estacion-R/manual_estilo/blob/main/Logo_PNG_Baja_Mesa%20de%20trabajo%201.png), pero no escribas 'Estaci√≥n R' ni otro texto extra.",
    "Evita fotograf√≠as, usa solo los logos o im√°genes originales ",
    "No agregues texto adicional ni hashtags. "
  )
  
  # Llama a la API de OpenAI/DALL¬∑E
  url <- "https://api.openai.com/v1/images/generations"
  body <- list(
    model = "dall-e-3",
    prompt = prompt,
    n = 1,
    size = "1024x1024"
  )
  res <- POST(
    url,
    add_headers(
      Authorization = paste("Bearer", api_key),
      `Content-Type` = "application/json"
    ),
    body = toJSON(body, auto_unbox = TRUE)
  )
  
  if (http_status(res)$category != "Success") {
    stop("No se pudo generar la imagen: ", content(res, as = "text"))
  }
  
  response <- content(res, as = "parsed")
  img_url <- response$data[[1]]$url
  
  download.file(img_url, destfile = output_path, mode = "wb")
  return(output_path)
}




##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##              Funci√≥n para chequear tuits con +280 caracteres             ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
chequear_tuit <- function(){
  
  # Link a la hoja de c√°lculo
  url <- "https://docs.google.com/spreadsheets/d/1OKGyVgAy1YhKfaGP_p0rwXWdVnQfovFRsgzo5qRQ3eo/edit#gid=0"
  
  # Habilito acceso p√∫blico
  googlesheets4::gs4_deauth()
  
  # Leo hoja de c√°lculo
  base <- googlesheets4::read_sheet(url, sheet = "Desarrollo")
  
  
  for (i in seq_along(base$web)) {
    
    base_tuit <- base[i, ]
    
    tuit <- armar_tuit(base = base_tuit)
    
    tryCatch(expr = {
      
      ### Si el tuit tiene m√°s de 280 caracteres
      if(nchar(tuit) > 500){ 
        
        cat(glue::glue("Ojota, el tuit nro {i} tiene {nchar(tuit)} caracteres"))
        
        if(!exists("tip_malo")){
          
          tip_malo <- readRDS("data/tip_malos.rds")
          
          tip_malo <- tip_malo |> 
            dplyr::bind_rows(base_tuit)
          
        } else {
          
          tip_malo <- tip_malo |> 
            dplyr::bind_rows(base_tuit)
        }
      }
      
      ### Si el tuit tiene menos de 280 caracteres
      if(nchar(tuit) <= 500) { 
        
        print(glue::glue("todo piola ameo con el tuit {i}"))
      }
      
    },
    
    error = function(e) {
      
      message(glue::glue("Revisar links de la web, tip, im√°gen, algo fall√≥ en el tuit nro {i}"))
    })
    
  }  
  
  
  if(exists("tip_malo")){
    
    return(tip_malo)
    
  } else {
    
    cat(glue::glue("Van {nrow(base)} tuits y todos est√°n joya"))
  }
}



##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##                                Achica urls                               ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

achicar_url <- function(link, linkPreview = FALSE) {
  
  if(!is.null(link)){
    
    api <- if(linkPreview) {"http://v.gd/create.php?format=json"} else {"http://is.gd/create.php?format=json"}
    query <- list(url = link)
    request <- httr::GET(api, query = query)
    contenido <- httr::content(request, as = "text", encoding = "utf-8")
    
    if(stringr::str_detect(contenido, "error") == FALSE){
      
      resultado <- jsonlite::fromJSON(contenido)
      
    } else {
      
      resultado <- link
    }
    
    return(resultado)
    
  } else {
    
    resultado <- NULL
    
    return(resultado)
  }
}


